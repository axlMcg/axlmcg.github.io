# Data Leakage

There is an issue in machine learning called data leakage.

Data leakage occurs when images from the training data set appear inside the test set. In a succesfully trained model this issue will cause issues where the success rate of the model is overtated by data that it has already classified.

In order to best avoid this images should be used that were not in the training and validation step done with fastai

```python
learn = vision_learner(dls, resnet18, metrics=error_rate)
learn.fine_tune(3)

```
For this additional dataset it is best to not scrape the internet as this will have data leakage from the same images accidentally being considered. therefore, before the learner is run a chunk of the images should be siphoned off as an isolated test data set for later.

Without doin this the below confusion matrix was generated:

